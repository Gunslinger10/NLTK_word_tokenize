# NLTK_word_tokenize
The Natural Language Toolkit Library (NLTK) was built to separate punctuation from words when tokenizing (splitting into parts).
